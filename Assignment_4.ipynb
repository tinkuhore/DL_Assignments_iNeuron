{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3400b0c",
   "metadata": {},
   "source": [
    "# 1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "\n",
    "Ans: TensorFlow is an open-source software library for high-performance numerical computation and machine learning, with features including flexible architecture, distributed computing, and deployment on multiple platforms. Other popular deep learning libraries include PyTorch, Keras, Theano, and Caffe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4967582",
   "metadata": {},
   "source": [
    "# 2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "Ans: While TensorFlow does include many of the numerical computation features found in NumPy, it is not a drop-in replacement for NumPy. The main difference between the two is that TensorFlow is designed for large-scale machine learning applications and includes features specifically tailored for deep learning tasks, such as automatic differentiation and GPU acceleration. Additionally, TensorFlow is built around the concept of computational graphs, which enable efficient computation of complex operations by breaking them down into smaller, parallelizable operations. NumPy, on the other hand, is a more general-purpose library for numerical computing, and while it can be used for machine learning, it does not include the same level of optimization for deep learning as TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1c160",
   "metadata": {},
   "source": [
    "# 3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "Ans : Yes, both tf.range(10) and tf.constant(np.arange(10)) will produce a Tensor with the same values of [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]. The first creates a TensorFlow Tensor using the tf.range function, which generates a sequence of numbers from 0 to one less than the input argument (in this case, 10). The second creates a TensorFlow Tensor from a NumPy array created using np.arange, which generates a sequence of numbers from 0 up to, but not including, the input argument (also 10 in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d6d4c",
   "metadata": {},
   "source": [
    "# 4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "\n",
    "Ans: In addition to regular tensors, TensorFlow also provides the following data structures:\n",
    "\n",
    "Variables: These are tensors whose values can be changed by the program during execution. They are often used to represent model parameters that need to be updated during training.\n",
    "\n",
    "Constants: These are tensors whose values cannot be changed during execution. They are often used to represent hyperparameters or other fixed values in a model.\n",
    "\n",
    "Placeholders: These are tensors that are used as input to a computation graph, but whose values are not known until runtime. They are often used to represent input data to a machine learning model.\n",
    "\n",
    "Sparse Tensors: These are tensors that store only the nonzero values of a tensor, along with their indices. They are used to represent sparse data structures, such as the adjacency matrix of a graph.\n",
    "\n",
    "Ragged Tensors: These are tensors that have variable-length dimensions, such as sequences of varying lengths. They are used to represent data that cannot be easily represented using regular tensors.\n",
    "\n",
    "TensorArrays: These are arrays of tensors that allow dynamic resizing during graph execution. They are often used to implement dynamic batching in sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d54d94",
   "metadata": {},
   "source": [
    "# 5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "Ans: In TensorFlow, a custom loss function can be defined either by writing a function or by subclassing the keras.losses.Loss class. Here's when to use each option:\n",
    "\n",
    "Writing a function: This is the simpler and more flexible option. You should use it when your loss function can be expressed as a mathematical formula that takes inputs (e.g., predicted and true values) and returns a scalar value (e.g., a mean or sum of differences). This option is also suitable when your loss function requires non-standard operations that are not easily implemented using existing TensorFlow functions.\n",
    "\n",
    "Subclassing the keras.losses.Loss class: This is a more advanced option that provides additional functionality, such as automatic handling of sample weights and reduction methods. You should use it when your loss function is more complex and requires additional customization beyond what is possible with a simple function. For example, if your loss function requires extra trainable parameters or if it needs to access other parts of the model during computation.\n",
    "\n",
    "In general, if your loss function can be expressed as a simple formula, it's better to define it using a function. If it requires more complex logic or customization, you can consider subclassing the keras.losses.Loss class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de67ec",
   "metadata": {},
   "source": [
    "# 6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "Ans: In TensorFlow, a custom metric can be defined either in a function or as a subclass of keras.metrics.Metric. Here's when to use each option:\n",
    "\n",
    "Defining a function: This is a simpler and more flexible option. You should use it when your metric can be expressed as a mathematical formula that takes inputs (e.g., predicted and true values) and returns a scalar value (e.g., accuracy, precision, recall, F1-score, etc.). This option is also suitable when your metric requires non-standard operations that are not easily implemented using existing TensorFlow functions.\n",
    "\n",
    "Subclassing the keras.metrics.Metric class: This is a more advanced option that provides additional functionality, such as tracking a state across batches and epochs, supporting sample weights and masking, and automatic handling of multi-label or multi-class problems. You should use it when your metric is more complex and requires additional customization beyond what is possible with a simple function. For example, if your metric requires extra trainable parameters or if it needs to access other parts of the model during computation.\n",
    "\n",
    "In general, if your metric can be expressed as a simple formula, it's better to define it using a function. If it requires more complex logic or customization, you can consider subclassing the keras.metrics.Metric class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c934bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class BinaryTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name='binary_true_positives', **kwargs):\n",
    "        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), dtype=tf.float32))\n",
    "        self.true_positives.assign_add(tp)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff959a",
   "metadata": {},
   "source": [
    "In this example, we define a custom metric called BinaryTruePositives that counts the number of true positives for a binary classification problem. We subclass the keras.metrics.Metric class and define three methods:\n",
    "\n",
    "__init__: We initialize the metric by calling the superclass's constructor and adding a new tf.Variable to store the number of true positives.\n",
    "\n",
    "update_state: We update the metric state by comparing the predicted and true labels using logical operators, computing the number of true positives, and updating the tf.Variable with the cumulative count.\n",
    "\n",
    "result: We return the final value of the metric, which is the number of true positives.\n",
    "\n",
    "reset_states: We reset the metric state at the end of each epoch.\n",
    "\n",
    "Once we have defined the BinaryTruePositives metric, we can use it in our model by passing it as a parameter to the compile method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2d940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:35:59.451200: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1865/1875 [============================>.] - ETA: 0s - loss: 0.1801 - binary_true_positives: 28197.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:36:02.396938: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.\n",
      "/home/tinku/.local/lib/python3.10/site-packages/keras/engine/training.py:2416: UserWarning: Metric BinaryTruePositives implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1798 - binary_true_positives: 28354.0000 - val_loss: 0.0916 - val_binary_true_positives: 4903.0000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1087 - binary_true_positives: 29296.0000 - val_loss: 0.0733 - val_binary_true_positives: 4946.0000\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0962 - binary_true_positives: 29392.0000 - val_loss: 0.0622 - val_binary_true_positives: 4959.0000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0865 - binary_true_positives: 29483.0000 - val_loss: 0.0594 - val_binary_true_positives: 4962.0000\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0820 - binary_true_positives: 29536.0000 - val_loss: 0.0584 - val_binary_true_positives: 4959.0000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0754 - binary_true_positives: 29596.0000 - val_loss: 0.0556 - val_binary_true_positives: 4970.0000\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0736 - binary_true_positives: 29610.0000 - val_loss: 0.0542 - val_binary_true_positives: 4973.0000\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0716 - binary_true_positives: 29619.0000 - val_loss: 0.0556 - val_binary_true_positives: 4992.0000\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0681 - binary_true_positives: 29680.0000 - val_loss: 0.0528 - val_binary_true_positives: 4974.0000\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0651 - binary_true_positives: 29678.0000 - val_loss: 0.0531 - val_binary_true_positives: 4987.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3201b7310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and binary true positives metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryTruePositives()])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784) / 255.0\n",
    "x_test = x_test.reshape(-1, 784) / 255.0\n",
    "\n",
    "# Convert the labels to binary (even vs odd digits)\n",
    "y_train = y_train % 2\n",
    "y_test = y_test % 2\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfbff7",
   "metadata": {},
   "source": [
    "# 7. When should you create a custom layer versus a custom model?\n",
    "\n",
    "Ans: You should create a custom layer in TensorFlow when you want to define a new type of computation that can be incorporated into existing models. For example, if you want to create a layer that applies a specific mathematical operation or transformation to the input data before passing it to the next layer in the model, you would create a custom layer. Custom layers can be easily integrated into existing TensorFlow models and can be reused across multiple models.\n",
    "\n",
    "On the other hand, you should create a custom model in TensorFlow when you want to define a completely new architecture or functionality that is not available in the existing models. For example, if you want to define a new type of neural network architecture or a new type of training algorithm, you would create a custom model. Custom models are more complex to implement than custom layers, but they provide more flexibility and can be used to tackle a wider range of problems.\n",
    "\n",
    "In general, if you are extending an existing model architecture or adding new functionality to an existing model, you should create a custom layer. If you are creating a new architecture or functionality from scratch, you should create a custom model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0f71c",
   "metadata": {},
   "source": [
    "# 8. What are some use cases that require writing your own custom training loop?\n",
    "\n",
    "Ans: Here are some use cases that may require writing your own custom training loop in TensorFlow:\n",
    "\n",
    "Advanced optimization techniques: If you want to use optimization techniques that are not available in the built-in TensorFlow optimizers, you may need to write your own training loop. For example, if you want to use second-order optimization methods like the Hessian or conjugate gradient, you may need to write your own training loop.\n",
    "\n",
    "Custom regularization: If you want to apply custom regularization techniques that are not available in the built-in TensorFlow layers or regularizers, you may need to write your own training loop. For example, if you want to apply a custom sparsity constraint or weight decay penalty, you may need to write your own training loop.\n",
    "\n",
    "Custom loss functions: If you want to use a custom loss function that is not available in the built-in TensorFlow losses, you may need to write your own training loop. For example, if you want to use a loss function that involves additional data inputs or external data sources, you may need to write your own training loop.\n",
    "\n",
    "Non-standard architectures: If you want to implement non-standard neural network architectures that are not easily expressed using the built-in TensorFlow layers or models, you may need to write your own training loop. For example, if you want to implement a network with dynamic layer creation or variable-length input sequences, you may need to write your own training loop.\n",
    "\n",
    "Advanced evaluation metrics: If you want to use evaluation metrics that are not available in the built-in TensorFlow metrics, you may need to write your own training loop. For example, if you want to compute metrics that require additional data inputs or external data sources, you may need to write your own training loop.\n",
    "\n",
    "In general, writing your own custom training loop gives you more control over the training process and allows you to implement advanced techniques and architectures that are not available in the built-in TensorFlow components. However, it also requires more expertise and can be more error-prone than using the built-in components, so it should only be attempted by experienced TensorFlow users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3de90",
   "metadata": {},
   "source": [
    "# 9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "\n",
    "Ans: Custom Keras components, such as layers, models, losses, and metrics, must be convertible to TensorFlow Functions to be used in a TensorFlow graph. TensorFlow Functions are a high-performance representation of TensorFlow computations that can be compiled and optimized for efficient execution on a wide range of hardware platforms.\n",
    "\n",
    "To be convertible to TensorFlow Functions, custom Keras components must adhere to certain rules and restrictions. Specifically, they must be written using TensorFlow operations and functions, and they must use TensorFlow data types and structures, such as tensors and variables. They must also avoid using certain types of Python constructs and language features that are not compatible with TensorFlow, such as loops and conditionals.\n",
    "\n",
    "However, within the constraints of the TensorFlow programming model, custom Keras components can contain arbitrary Python code and logic. For example, custom loss functions and metrics can include complex mathematical computations and logic that goes beyond simple arithmetic operations on tensors.\n",
    "\n",
    "In summary, custom Keras components must be convertible to TensorFlow Functions to be used in a TensorFlow graph, but within that constraint, they can contain arbitrary Python code and logic as long as it is compatible with the TensorFlow programming model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0736f",
   "metadata": {},
   "source": [
    "# 10. What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "\n",
    "Ans: Here are some main rules to respect if you want a function to be convertible to a TensorFlow Function:\n",
    "\n",
    "Use only TensorFlow operations and functions: TensorFlow Functions can only include TensorFlow operations and functions, not Python functions or external libraries. This is because TensorFlow Functions need to be compiled and optimized for efficient execution on a wide range of hardware platforms, which requires a well-defined and restricted set of operations and functions.\n",
    "\n",
    "Use only TensorFlow data types and structures: TensorFlow Functions can only use TensorFlow data types and structures, such as tensors and variables, not Python data types or structures. This is because TensorFlow Functions need to be able to manage and optimize memory usage, data transfer, and other low-level aspects of computation.\n",
    "\n",
    "Avoid using Python constructs that are not convertible to TensorFlow: TensorFlow Functions can only use Python constructs that can be converted to TensorFlow operations and functions. This includes loops, conditionals, and other constructs that are not easily expressible in TensorFlow. If you need to use these constructs, you may need to convert them to TensorFlow operations using TensorFlow control flow constructs like tf.while_loop and tf.cond.\n",
    "\n",
    "Minimize side effects: TensorFlow Functions should avoid side effects, such as printing to the console or modifying global state, as these can interfere with TensorFlow's computation and optimization process. If you need to perform side effects, you may need to use TensorFlow control flow constructs like tf.py_function to wrap your side-effecting code in a TensorFlow-compatible way.\n",
    "\n",
    "Design for reusability: TensorFlow Functions should be designed to be reusable and composable, so that they can be easily combined with other TensorFlow operations and functions to build complex models and computations. This includes following good software engineering practices like modularization, encapsulation, and separation of concerns.\n",
    "\n",
    "By respecting these rules, you can ensure that your function can be converted to a TensorFlow Function and used in a TensorFlow graph for efficient computation and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86e3f5",
   "metadata": {},
   "source": [
    "# 11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "Ans: ou would need to create a dynamic Keras model when the shape of the input data or the size of the model layers is not fixed at design time. This can happen in various scenarios, such as:\n",
    "\n",
    "When dealing with variable-length sequences of data, such as sentences or time series.\n",
    "When building models that require dynamic control flow, such as recurrent neural networks with varying sequence lengths.\n",
    "When building models with conditional branches or loops, such as GANs or reinforcement learning models.\n",
    "To create a dynamic Keras model, you can define the model using the tf.keras.Input function to specify the shape of the input data as a variable-length tuple. You can also use the tf.keras.layers.InputLayer class to define the input layer of the model.\n",
    "\n",
    "In addition, you can use the tf.keras.backend.shape function and other dynamic tensor operations to compute the shape of the model layers at runtime.\n",
    "\n",
    "While dynamic models offer more flexibility in terms of handling variable-length input data and dynamic control flow, they also come with some limitations and trade-offs, such as:\n",
    "\n",
    "Dynamic models may be slower to run than static models because the shape of the model has to be computed at runtime.\n",
    "Dynamic models may be harder to optimize and distribute across multiple GPUs or devices, as they require more complex graph computations.\n",
    "Dynamic models may not be compatible with some TensorFlow features, such as graph optimization or static shape inference.\n",
    "Dynamic models may require more careful management of memory and resources, as the shape of the model and the size of the input data can vary at runtime.\n",
    "For these reasons, it's not always necessary or optimal to make all your models dynamic. It depends on the specific requirements of your problem and the characteristics of your data. If your data has a fixed shape and size, or if you're building a simple feedforward network, a static model may be sufficient and more efficient. However, if you're dealing with variable-length input data or complex control flow, a dynamic model may be necessary to achieve good performance and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
